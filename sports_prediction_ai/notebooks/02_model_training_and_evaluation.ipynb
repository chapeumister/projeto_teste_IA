{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Model Training, Evaluation, and Prediction Pipeline\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Training a simple model using `model_training.py`.\n",
    "2. Evaluating the model using `model_evaluation.py`.\n",
    "3. Running the end-to-end daily prediction pipeline using `prediction_pipeline.py`.\n",
    "\n",
    "**Note:** This notebook uses dummy data/features for model training and prediction as feature engineering is not fully implemented. The prediction pipeline also requires `FOOTBALL_DATA_API_KEY` for fetching live matches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Add src directory to Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "src_path = os.path.join(project_root, 'src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "try:\n",
    "    from model_training import split_data, train_random_forest, load_model # Using Random Forest as example\n",
    "    from model_evaluation import get_classification_metrics, plot_confusion_matrix\n",
    "    from prediction_pipeline import predict_daily_matches, generate_features_for_prediction # For prediction part\n",
    "    # from data_preprocessing import preprocess_match_data # If we need to re-process some data\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing modules: {e}\")\n",
    "    print(\"Make sure 'src' is in sys.path and __init__.py files are present.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Training (Example with Dummy Data)\n",
    "\n",
    "We'll create a synthetic dataset and train a Random Forest model. In a real scenario, this data would come from `01_data_collection_and_preprocessing.ipynb` after extensive feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy data for training\n",
    "num_samples = 200\n",
    "data = {\n",
    "    'feature1': np.random.rand(num_samples),\n",
    "    'feature2': np.random.rand(num_samples) * 10,\n",
    "    'feature3': np.random.randint(0, 5, num_samples),\n",
    "    # New form features (dummy values)\n",
    "    'home_form_W': np.random.randint(0, 3, num_samples), # Wins in last 5 games (0-2 typical for dummy)\n",
    "    'home_form_D': np.random.randint(0, 2, num_samples), # Draws in last 5 games (0-1)\n",
    "    'home_form_L': np.random.randint(0, 3, num_samples), # Losses \n",
    "    'home_form_games_played': np.full(num_samples, 5),\n",
    "    'away_form_W': np.random.randint(0, 3, num_samples),\n",
    "    'away_form_D': np.random.randint(0, 2, num_samples),\n",
    "    'away_form_L': np.random.randint(0, 3, num_samples),\n",
    "    'away_form_games_played': np.full(num_samples, 5),\n",
    "    # Target: 0 for Home Win, 1 for Draw, 2 for Away Win\n",
    "    'result_label': np.random.choice([0, 1, 2], num_samples, p=[0.45, 0.25, 0.30]) \n",
    "}\n",
    "training_df = pd.DataFrame(data)\n",
    "\n",
    "# Ensure consistent sum for W, D, L for played games (example for home team)\n",
    "training_df['home_form_L'] = training_df.apply(lambda row: max(0, row['home_form_games_played'] - row['home_form_W'] - row['home_form_D']), axis=1)\n",
    "training_df['away_form_L'] = training_df.apply(lambda row: max(0, row['away_form_games_played'] - row['away_form_W'] - row['away_form_D']), axis=1)\n",
    "\n",
    "print(\"Dummy Training Data Head (with form features):\")\n",
    "print(training_df.head())\n",
    "print(\"\\nTarget Distribution:\")\n",
    "print(training_df['result_label'].value_counts(normalize=True))\n",
    "\n",
    "feature_columns = [\n",
    "    'feature1', 'feature2', 'feature3',\n",
    "    'home_form_W', 'home_form_D', 'home_form_L', 'home_form_games_played',\n",
    "    'away_form_W', 'away_form_D', 'away_form_L', 'away_form_games_played'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "if not training_df.empty:\n",
    "    # The split_data function in model_training.py uses all columns except target as features.\n",
    "    # So, X_train will automatically include the new form features added to training_df.\n",
    "    X_train, X_test, y_train, y_test = split_data(training_df, target_column='result_label', test_size=0.25)\n",
    "    print(f\"\\nTraining set size: {X_train.shape[0]}, Test set size: {X_test.shape[0]}\")\n",
    "    print(f\"Features in X_train: {X_train.columns.tolist()}\")\n",
    "\n",
    "    # Train a Random Forest model\n",
    "    rf_model_filename = \"example_rf_model_with_form.pkl\" # New model name\n",
    "    trained_model = train_random_forest(X_train, y_train, model_filename=rf_model_filename)\n",
    "    print(f\"\\nModel trained: {trained_model}\")\n",
    "else:\n",
    "    print(\"Training DataFrame is empty. Skipping training and evaluation.\")\n",
    "    X_test, y_test, trained_model = pd.DataFrame(), pd.Series(dtype='float64'), None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if trained_model and not X_test.empty:\n",
    "    print(\"\\nEvaluating model on the test set...\")\n",
    "    # Ensure X_test has the same features as X_train (split_data handles this)\n",
    "    y_pred = trained_model.predict(X_test)\n",
    "    y_prob = trained_model.predict_proba(X_test)\n",
    "\n",
    "    class_labels = sorted(training_df['result_label'].unique())\n",
    "    target_names = [\"Home Win (0)\", \"Draw (1)\", \"Away Win (2)\"] # More descriptive\n",
    "\n",
    "    metrics = get_classification_metrics(y_test, y_pred, y_prob, average='weighted', labels=class_labels, target_names=target_names)\n",
    "\n",
    "    plot_confusion_matrix(y_test, y_pred, labels=class_labels, display_labels=target_names, filename=\"example_notebook_cm_with_form.png\")\n",
    "else:\n",
    "    print(\"Model not trained or test data is empty. Skipping evaluation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Running the Daily Prediction Pipeline\n",
    "\n",
    "This part uses the `prediction_pipeline.py` script. Key changes to be aware of:\n",
    "- The pipeline now incorporates **team form features**.\n",
    "- This means `generate_features_for_prediction` (called by `predict_daily_matches`) uses `engineer_form_features`.\n",
    "- `engineer_form_features` requires **historical match data**. The pipeline attempts to load this from `data/historical_matches_sample.csv`. If not found, it uses an internal minimal dummy dataset.\n",
    "\n",
    "**Requires:**\n",
    "- A trained model file (e.g., `example_rf_model_with_form.pkl` saved from the step above). The model must be trained with the same features the pipeline generates (including form features and any other base features like 'feature1', 'feature2', 'feature3' if the pipeline's dummy data includes them).\n",
    "- `FOOTBALL_DATA_API_KEY` environment variable for fetching actual daily matches.\n",
    "- Optionally, `APISPORTS_API_KEY` if you want to test with that data source via the pipeline script (though the notebook call below uses football-data.org by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "api_key_notebook = os.getenv(\"FOOTBALL_DATA_API_KEY\", \"YOUR_API_TOKEN\")\n",
    "\n",
    "print(f\"Running prediction pipeline for date: {today_str}\")\n",
    "print(f\"Using model: {rf_model_filename}\") # This should be the model trained with form features\n",
    "print(f\"API Key for football-data.org available: {'Yes' if api_key_notebook != 'YOUR_API_TOKEN' else 'No (will not fetch real data)'}\")\n",
    "\n",
    "model_to_use_in_pipeline = rf_model_filename \n",
    "model_path_pipeline = os.path.join(project_root, 'models', model_to_use_in_pipeline)\n",
    "\n",
    "if not os.path.exists(model_path_pipeline):\n",
    "    print(f\"ERROR: Model {model_to_use_in_pipeline} not found at {model_path_pipeline}.\")\n",
    "    print(\"Please ensure the model from training step was saved correctly or use an existing model file.\")\n",
    "else:\n",
    "    # The prediction_pipeline.py's generate_features_for_prediction now calls engineer_form_features.\n",
    "    # It also adds dummy 'feature1', 'feature2', 'feature3' for consistency with model_training.py.\n",
    "    # Our trained model (example_rf_model_with_form.pkl) includes these features.\n",
    "    print(\"\\nPipeline will attempt to load historical data from '../data/historical_matches_sample.csv' or use a fallback.\")\n",
    "    predict_daily_matches(date_str=today_str, model_filename=model_to_use_in_pipeline, api_key=api_key_notebook, source_api='football-data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Considerations for Real-World Usage:\n",
    "\n",
    "1.  **Feature Consistency**: The features generated by `generate_features_for_prediction` in `prediction_pipeline.py` (which now includes form features and potentially other base features) *must* exactly match the features used to train the loaded model. The examples are aligned, but custom models need careful handling.\n",
    "2.  **Historical Data**: The quality and availability of historical data (like `data/historical_matches_sample.csv`) are crucial for meaningful form features. The current sample CSV is very small.\n",
    "3.  **Model Retraining**: Models should be periodically retrained with new data.\n",
    "4.  **API Key Management**: Securely manage API keys."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.x.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
